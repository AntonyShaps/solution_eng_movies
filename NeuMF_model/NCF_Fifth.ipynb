{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2b5232",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79213841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-31 23:11:53,314\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-05-31 23:11:53,578\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "#import recbole\n",
    "#print(recbole.__version__)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from recbole.quick_start import run_recbole\n",
    "from recbole.model.general_recommender import NeuMF\n",
    "from recbole.config import Config\n",
    "from recbole.data.interaction import Interaction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f382da",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffcf633",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bda046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training NeuMF on movielens...\n",
      "Data Split: Train=90.0%, Valid=5.0%, Test=5.0%\n",
      "Task: ranking, Loss: BPR\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_dict = {\n",
    "    'model': 'NeuMF',\n",
    "    'dataset': 'movielens',\n",
    "    'data_path': './dataset/',\n",
    "\n",
    "  'field_separator': '\\t',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "    'LABEL_FIELD': 'rating', \n",
    "    'threshold': {'rating': 4.5}, \n",
    "\n",
    "    'eval_task': 'ranking', \n",
    "    'normalize_field': {},\n",
    "    'loss_type': 'BPR', \n",
    "\n",
    "    'eval_args': {\n",
    "        'split': {'RS': [0.9, 0.05, 0.05]},\n",
    "        'order': 'TO',\n",
    "        'group_by': 'user',\n",
    "        'mode': {'valid': 'uni100', 'test': 'uni100'},\n",
    "        'neg_sample_args': None, \n",
    "        'topk': [3, 10, 20], \n",
    "    },\n",
    "    'metrics': ['Recall', 'NDCG', 'MRR'], \n",
    "    'valid_metric': 'NDCG@10',\n",
    "    'valid_metric_bigger': True,\n",
    "\n",
    "    'train_neg_sample_args': {'distribution': 'uniform', 'sample_num': 1}, \n",
    "    'mf_embedding_size': 64,\n",
    "    'mlp_embedding_size': 64,\n",
    "    'layers': [128, 64, 32],\n",
    "    'dropout_prob': 0.3,\n",
    "\n",
    "    'learning_rate': 0.001,\n",
    "    'train_batch_size': 1024,\n",
    "    'epochs': 50,\n",
    "    'eval_step': 5,\n",
    "    'stopping_step': 4,\n",
    "\n",
    "    'eval_batch_size': 512,\n",
    "    'log_wandb': False,\n",
    "    'show_progress': False,\n",
    "    'log_file': 'main_NeuMF.txt',\n",
    "    'checkpoint_dir': 'main_NeuMF',\n",
    "}\n",
    "\n",
    "print(f\"\\nTraining {config_dict['model']} on {config_dict['dataset']}...\")\n",
    "print(f\"Data Split: Train={config_dict['eval_args']['split']['RS'][0]*100}%, Valid={config_dict['eval_args']['split']['RS'][1]*100}%, Test={config_dict['eval_args']['split']['RS'][2]*100}%\")\n",
    "print(f\"Task: {config_dict['eval_task']}, Loss: {config_dict['loss_type']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a2d50e",
   "metadata": {},
   "source": [
    "### Execute model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3038b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31 May 23:11    INFO  ['/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/ipykernel_launcher.py', '--f=/Users/vitalii/Library/Jupyter/runtime/kernel-v3edaf55caceffadd78528081992aeb7a36fe4e60e.json']\n",
      "31 May 23:11    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ./dataset/movielens\n",
      "checkpoint_dir = main_NeuMF\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 1024\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 5\n",
      "stopping_step = 4\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.9, 0.05, 0.05]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'uni100', 'test': 'uni100'}, 'neg_sample_args': None, 'topk': [3, 10, 20]}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'NDCG', 'MRR']\n",
      "topk = [10]\n",
      "valid_metric = NDCG@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 512\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = rating\n",
      "threshold = {'rating': 4.5}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = {}\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "mf_embedding_size = 64\n",
      "mlp_embedding_size = 64\n",
      "mlp_hidden_size = [128, 64]\n",
      "dropout_prob = 0.3\n",
      "mf_train = True\n",
      "mlp_train = True\n",
      "use_pretrain = False\n",
      "mf_pretrain_path = None\n",
      "mlp_pretrain_path = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "eval_task = ranking\n",
      "loss_type = BPR\n",
      "layers = [128, 64, 32]\n",
      "log_file = main_NeuMF.txt\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 100}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 100}\n",
      "\n",
      "\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "31 May 23:14    INFO  movielens\n",
      "The number of users: 162542\n",
      "Average actions of users: 153.8079253849798\n",
      "The number of items: 59048\n",
      "Average actions of items: 423.39312750859483\n",
      "The number of inters: 25000094\n",
      "The sparsity of the dataset: 99.73952211909084%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "31 May 23:14    INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "31 May 23:14    INFO  [Evaluation]: eval_batch_size = [512] eval_args: [{'split': {'RS': [0.9, 0.05, 0.05]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'uni100', 'test': 'uni100'}, 'neg_sample_args': None, 'topk': [3, 10, 20]}]\n",
      "31 May 23:14    INFO  NeuMF(\n",
      "  (user_mf_embedding): Embedding(162542, 64)\n",
      "  (item_mf_embedding): Embedding(59048, 64)\n",
      "  (user_mlp_embedding): Embedding(162542, 64)\n",
      "  (item_mlp_embedding): Embedding(59048, 64)\n",
      "  (mlp_layers): MLPLayers(\n",
      "    (mlp_layers): Sequential(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 28388417\n",
      "31 May 23:14    INFO  FLOPs: 24960.0\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "31 May 23:35    INFO  epoch 0 training [time: 1224.11s, train loss: 6181.0007]\n",
      "31 May 23:55    INFO  epoch 1 training [time: 1221.76s, train loss: 4719.6027]\n",
      "01 Jun 00:15    INFO  epoch 2 training [time: 1223.25s, train loss: 4335.5745]\n",
      "01 Jun 00:36    INFO  epoch 3 training [time: 1230.27s, train loss: 4155.9738]\n",
      "01 Jun 00:56    INFO  epoch 4 training [time: 1229.79s, train loss: 4046.8818]\n",
      "01 Jun 01:01    INFO  epoch 4 evaluating [time: 264.53s, valid_score: 0.737700]\n",
      "01 Jun 01:01    INFO  valid result: \n",
      "recall@10 : 0.7866    ndcg@10 : 0.7377    mrr@10 : 0.7821\n",
      "01 Jun 01:01    INFO  Saving current: main_NeuMF/NeuMF-May-31-2025_23-14-35.pth\n",
      "01 Jun 01:21    INFO  epoch 5 training [time: 1227.85s, train loss: 3973.8836]\n",
      "01 Jun 01:42    INFO  epoch 6 training [time: 1228.07s, train loss: 3919.7312]\n",
      "01 Jun 02:02    INFO  epoch 7 training [time: 1228.80s, train loss: 3874.4565]\n",
      "01 Jun 02:23    INFO  epoch 8 training [time: 1226.50s, train loss: 3828.9258]\n",
      "01 Jun 02:43    INFO  epoch 9 training [time: 1229.41s, train loss: 3784.1939]\n",
      "01 Jun 02:47    INFO  epoch 9 evaluating [time: 268.10s, valid_score: 0.745100]\n",
      "01 Jun 02:47    INFO  valid result: \n",
      "recall@10 : 0.7898    ndcg@10 : 0.7451    mrr@10 : 0.7913\n",
      "01 Jun 02:47    INFO  Saving current: main_NeuMF/NeuMF-May-31-2025_23-14-35.pth\n",
      "01 Jun 03:08    INFO  epoch 10 training [time: 1228.54s, train loss: 3747.1358]\n",
      "01 Jun 03:28    INFO  epoch 11 training [time: 1226.52s, train loss: 3718.9498]\n",
      "01 Jun 03:49    INFO  epoch 12 training [time: 1224.05s, train loss: 3691.0721]\n",
      "01 Jun 04:09    INFO  epoch 13 training [time: 1232.66s, train loss: 3670.3253]\n",
      "01 Jun 04:30    INFO  epoch 14 training [time: 1219.43s, train loss: 3656.9919]\n",
      "01 Jun 04:34    INFO  epoch 14 evaluating [time: 262.96s, valid_score: 0.747300]\n",
      "01 Jun 04:34    INFO  valid result: \n",
      "recall@10 : 0.7909    ndcg@10 : 0.7473    mrr@10 : 0.7931\n",
      "01 Jun 04:34    INFO  Saving current: main_NeuMF/NeuMF-May-31-2025_23-14-35.pth\n",
      "01 Jun 04:54    INFO  epoch 15 training [time: 1214.96s, train loss: 3641.8129]\n",
      "01 Jun 05:15    INFO  epoch 16 training [time: 1225.05s, train loss: 3625.2509]\n",
      "01 Jun 05:35    INFO  epoch 17 training [time: 1225.47s, train loss: 3606.5584]\n",
      "01 Jun 05:56    INFO  epoch 18 training [time: 1225.59s, train loss: 3587.5717]\n",
      "01 Jun 06:16    INFO  epoch 19 training [time: 1226.95s, train loss: 3572.4533]\n",
      "01 Jun 06:20    INFO  epoch 19 evaluating [time: 266.45s, valid_score: 0.747900]\n",
      "01 Jun 06:20    INFO  valid result: \n",
      "recall@10 : 0.7916    ndcg@10 : 0.7479    mrr@10 : 0.7932\n",
      "01 Jun 06:20    INFO  Saving current: main_NeuMF/NeuMF-May-31-2025_23-14-35.pth\n",
      "01 Jun 06:41    INFO  epoch 20 training [time: 1227.39s, train loss: 3566.4221]\n",
      "01 Jun 07:01    INFO  epoch 21 training [time: 1227.15s, train loss: 3559.4256]\n",
      "01 Jun 07:22    INFO  epoch 22 training [time: 1228.25s, train loss: 3557.8103]\n",
      "01 Jun 07:42    INFO  epoch 23 training [time: 1225.04s, train loss: 3565.1824]\n",
      "01 Jun 08:03    INFO  epoch 24 training [time: 1224.26s, train loss: 3570.5749]\n",
      "01 Jun 08:07    INFO  epoch 24 evaluating [time: 265.35s, valid_score: 0.748400]\n",
      "01 Jun 08:07    INFO  valid result: \n",
      "recall@10 : 0.7913    ndcg@10 : 0.7484    mrr@10 : 0.7946\n",
      "01 Jun 08:07    INFO  Saving current: main_NeuMF/NeuMF-May-31-2025_23-14-35.pth\n",
      "01 Jun 08:28    INFO  epoch 25 training [time: 1225.84s, train loss: 3568.6953]\n",
      "01 Jun 08:48    INFO  epoch 26 training [time: 1223.32s, train loss: 3566.8465]\n",
      "01 Jun 09:08    INFO  epoch 27 training [time: 1225.80s, train loss: 3544.5900]\n",
      "01 Jun 09:29    INFO  epoch 28 training [time: 1226.14s, train loss: 3528.6121]\n",
      "01 Jun 09:49    INFO  epoch 29 training [time: 1224.86s, train loss: 3512.2713]\n",
      "01 Jun 09:54    INFO  epoch 29 evaluating [time: 265.98s, valid_score: 0.753100]\n",
      "01 Jun 09:54    INFO  valid result: \n",
      "recall@10 : 0.793    ndcg@10 : 0.7531    mrr@10 : 0.8003\n",
      "01 Jun 09:54    INFO  Saving current: main_NeuMF/NeuMF-May-31-2025_23-14-35.pth\n",
      "01 Jun 10:14    INFO  epoch 30 training [time: 1229.23s, train loss: 3500.1119]\n",
      "01 Jun 10:35    INFO  epoch 31 training [time: 1225.53s, train loss: 3488.2576]\n",
      "01 Jun 10:55    INFO  epoch 32 training [time: 1224.73s, train loss: 3477.0577]\n",
      "01 Jun 11:16    INFO  epoch 33 training [time: 1248.48s, train loss: 3465.1740]\n",
      "01 Jun 11:36    INFO  epoch 34 training [time: 1237.08s, train loss: 3453.8931]\n",
      "01 Jun 11:41    INFO  epoch 34 evaluating [time: 262.67s, valid_score: 0.752300]\n",
      "01 Jun 11:41    INFO  valid result: \n",
      "recall@10 : 0.7933    ndcg@10 : 0.7523    mrr@10 : 0.7971\n",
      "01 Jun 12:01    INFO  epoch 35 training [time: 1237.84s, train loss: 3456.7828]\n",
      "01 Jun 12:22    INFO  epoch 36 training [time: 1238.02s, train loss: 3454.8759]\n",
      "01 Jun 12:43    INFO  epoch 37 training [time: 1235.39s, train loss: 3459.4884]\n",
      "01 Jun 13:03    INFO  epoch 38 training [time: 1238.72s, train loss: 3464.2549]\n",
      "01 Jun 13:24    INFO  epoch 39 training [time: 1229.63s, train loss: 3471.0920]\n",
      "01 Jun 13:28    INFO  epoch 39 evaluating [time: 263.23s, valid_score: 0.754300]\n",
      "01 Jun 13:28    INFO  valid result: \n",
      "recall@10 : 0.7934    ndcg@10 : 0.7543    mrr@10 : 0.8012\n",
      "01 Jun 13:28    INFO  Saving current: main_NeuMF/NeuMF-May-31-2025_23-14-35.pth\n",
      "01 Jun 13:49    INFO  epoch 40 training [time: 1235.32s, train loss: 3484.1481]\n",
      "01 Jun 14:10    INFO  epoch 41 training [time: 1262.44s, train loss: 3488.6162]\n",
      "01 Jun 14:30    INFO  epoch 42 training [time: 1237.84s, train loss: 3496.0129]\n",
      "01 Jun 14:51    INFO  epoch 43 training [time: 1233.60s, train loss: 3487.2387]\n",
      "01 Jun 15:12    INFO  epoch 44 training [time: 1235.97s, train loss: 3482.3077]\n",
      "01 Jun 15:16    INFO  epoch 44 evaluating [time: 263.72s, valid_score: 0.752200]\n",
      "01 Jun 15:16    INFO  valid result: \n",
      "recall@10 : 0.7928    ndcg@10 : 0.7522    mrr@10 : 0.7986\n",
      "01 Jun 15:37    INFO  epoch 45 training [time: 1242.37s, train loss: 3474.9558]\n",
      "01 Jun 15:57    INFO  epoch 46 training [time: 1237.09s, train loss: 3463.6348]\n",
      "01 Jun 16:18    INFO  epoch 47 training [time: 1234.79s, train loss: 3462.0604]\n",
      "01 Jun 16:38    INFO  epoch 48 training [time: 1235.07s, train loss: 3457.9282]\n",
      "01 Jun 16:59    INFO  epoch 49 training [time: 1244.08s, train loss: 3461.1759]\n",
      "01 Jun 17:04    INFO  epoch 49 evaluating [time: 263.60s, valid_score: 0.750900]\n",
      "01 Jun 17:04    INFO  valid result: \n",
      "recall@10 : 0.7913    ndcg@10 : 0.7509    mrr@10 : 0.7989\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/_weights_only_unpickler.py:549: UserWarning: Detected pickle protocol 4 in the checkpoint, which was not the default pickle protocol used by `torch.load` (2). The weights_only Unpickler might not support all instructions implemented by this protocol, please file an issue for adding support if you encounter this.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_recbole\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining complete. Logs saved to:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[33m'\u001b[39m\u001b[33mlog_file\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/quick_start/quick_start.py:153\u001b[39m, in \u001b[36mrun_recbole\u001b[39m\u001b[34m(model, dataset, config_file_list, config_dict, saved, queue)\u001b[39m\n\u001b[32m    148\u001b[39m best_valid_score, best_valid_result = trainer.fit(\n\u001b[32m    149\u001b[39m     train_data, valid_data, saved=saved, show_progress=config[\u001b[33m\"\u001b[39m\u001b[33mshow_progress\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    150\u001b[39m )\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# model evaluation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m test_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43msaved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshow_progress\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m environment_tb = get_environment(config)\n\u001b[32m    158\u001b[39m logger.info(\n\u001b[32m    159\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe running environment of this training is as follows:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m     + environment_tb.draw()\n\u001b[32m    161\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/trainer/trainer.py:583\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_data, load_best_model, model_file, show_progress)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load_best_model:\n\u001b[32m    582\u001b[39m     checkpoint_file = model_file \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.saved_model_file\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.load_state_dict(checkpoint[\u001b[33m\"\u001b[39m\u001b[33mstate_dict\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    585\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.load_other_parameter(checkpoint.get(\u001b[33m\"\u001b[39m\u001b[33mother_parameter\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/serialization.py:1524\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1516\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1517\u001b[39m                     opened_zipfile,\n\u001b[32m   1518\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1521\u001b[39m                     **pickle_load_args,\n\u001b[32m   1522\u001b[39m                 )\n\u001b[32m   1523\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1526\u001b[39m             opened_zipfile,\n\u001b[32m   1527\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m             **pickle_load_args,\n\u001b[32m   1531\u001b[39m         )\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "run_recbole(config_dict=config_dict)\n",
    "\n",
    "print(\"\\nTraining complete. Logs saved to:\")\n",
    "print(f\"  {config_dict['log_file']}\")\n",
    "print(f\"Best model saved in: {config_dict['checkpoint_dir']}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
