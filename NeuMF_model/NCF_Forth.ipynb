{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2b5232",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79213841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-31 11:05:16,638\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-05-31 11:05:16,923\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "#import recbole\n",
    "#print(recbole.__version__)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from recbole.quick_start import run_recbole\n",
    "from recbole.model.general_recommender import NeuMF\n",
    "from recbole.config import Config\n",
    "from recbole.data.interaction import Interaction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f382da",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffcf633",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bda046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training NeuMF on movielens...\n",
      "Data Split: Train=90.0%, Valid=5.0%, Test=5.0%\n",
      "Task: ranking, Loss: BPR\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_dict = {\n",
    "    'model': 'NeuMF',\n",
    "    'dataset': 'movielens',\n",
    "    'data_path': './dataset/',\n",
    "\n",
    "  'field_separator': '\\t',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "    'LABEL_FIELD': 'rating', # Still refers to the 'rating' column\n",
    "    'threshold': {'rating': 4.5}, # <-- NEW: Ratings >= 4.5 are positive interactions for ranking\n",
    "\n",
    "    'eval_task': 'ranking', # <-- CHANGED: Problem now framed as a ranking task\n",
    "    'normalize_field': {},\n",
    "    'loss_type': 'BPR', # <-- CHANGED: BPRLoss for ranking problems\n",
    "\n",
    "    'eval_args': {\n",
    "        'split': {'RS': [0.9, 0.05, 0.05]},\n",
    "        'order': 'TO',\n",
    "        'group_by': 'user',\n",
    "        'mode': {'valid': 'uni10', 'test': 'uni10'},\n",
    "        'neg_sample_args': None, # No specific negative sampling for evaluation metrics, RecBole handles this.\n",
    "        'topk': [10, 20, 50], # <-- NEW: K values for ranking metrics (e.g., Recall@10, NDCG@20)\n",
    "    },\n",
    "    # Metrics for Ranking task\n",
    "    'metrics': ['Recall', 'NDCG', 'MRR'], # <-- CHANGED: Ranking metrics\n",
    "    'valid_metric': 'NDCG@10', # <-- CHANGED: Use a ranking metric for validation\n",
    "    'valid_metric_bigger': True, # For ranking metrics, bigger is better\n",
    "\n",
    "    'train_neg_sample_args': {'distribution': 'uniform', 'sample_num': 1}, # <-- ESSENTIAL for BPRLoss\n",
    "    # NeuMF parameters (same as before)\n",
    "    'mf_embedding_size': 64,\n",
    "    'mlp_embedding_size': 64,\n",
    "    'layers': [128, 64, 32],\n",
    "    'dropout_prob': 0.3,\n",
    "\n",
    "    'learning_rate': 0.001,\n",
    "    'train_batch_size': 1024,\n",
    "    'epochs': 14,\n",
    "    'eval_step': 5,\n",
    "\n",
    "    'eval_batch_size': 512,\n",
    "    'log_wandb': False,\n",
    "    'show_progress': False,\n",
    "    'log_file': 'recbole_ml25m_neumf_ranking_log.txt', # Changed log file name\n",
    "    'checkpoint_dir': 'saved_models_ml25m_ranking', # Changed checkpoint dir\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "}\n",
    "\n",
    "print(f\"\\nTraining {config_dict['model']} on {config_dict['dataset']}...\")\n",
    "print(f\"Data Split: Train={config_dict['eval_args']['split']['RS'][0]*100}%, Valid={config_dict['eval_args']['split']['RS'][1]*100}%, Test={config_dict['eval_args']['split']['RS'][2]*100}%\")\n",
    "print(f\"Task: {config_dict['eval_task']}, Loss: {config_dict['loss_type']}\")\n",
    "print(f\"Device: {config_dict['device']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a2d50e",
   "metadata": {},
   "source": [
    "### Execute model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3038b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31 May 11:06    INFO  ['/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/ipykernel_launcher.py', '--f=/Users/vitalii/Library/Jupyter/runtime/kernel-v3e40b363fe3b61142012798ea81be6c665db35280.json']\n",
      "31 May 11:06    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ./dataset/movielens\n",
      "checkpoint_dir = saved_models_ml25m_ranking\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 14\n",
      "train_batch_size = 1024\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 5\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.9, 0.05, 0.05]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'uni10', 'test': 'uni10'}, 'neg_sample_args': None, 'topk': [10, 20, 50]}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'NDCG', 'MRR']\n",
      "topk = [10]\n",
      "valid_metric = NDCG@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 512\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = rating\n",
      "threshold = {'rating': 4.5}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = {}\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "mf_embedding_size = 64\n",
      "mlp_embedding_size = 64\n",
      "mlp_hidden_size = [128, 64]\n",
      "dropout_prob = 0.3\n",
      "mf_train = True\n",
      "mlp_train = True\n",
      "use_pretrain = False\n",
      "mf_pretrain_path = None\n",
      "mlp_pretrain_path = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "eval_task = ranking\n",
      "loss_type = BPR\n",
      "layers = [128, 64, 32]\n",
      "log_file = recbole_ml25m_neumf_ranking_log.txt\n",
      "device = cpu\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 10}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 10}\n",
      "\n",
      "\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "31 May 11:08    INFO  movielens\n",
      "The number of users: 162542\n",
      "Average actions of users: 153.8079253849798\n",
      "The number of items: 59048\n",
      "Average actions of items: 423.39312750859483\n",
      "The number of inters: 25000094\n",
      "The sparsity of the dataset: 99.73952211909084%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "31 May 11:08    INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "31 May 11:08    INFO  [Evaluation]: eval_batch_size = [512] eval_args: [{'split': {'RS': [0.9, 0.05, 0.05]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'uni10', 'test': 'uni10'}, 'neg_sample_args': None, 'topk': [10, 20, 50]}]\n",
      "31 May 11:08    INFO  NeuMF(\n",
      "  (user_mf_embedding): Embedding(162542, 64)\n",
      "  (item_mf_embedding): Embedding(59048, 64)\n",
      "  (user_mlp_embedding): Embedding(162542, 64)\n",
      "  (item_mlp_embedding): Embedding(59048, 64)\n",
      "  (mlp_layers): MLPLayers(\n",
      "    (mlp_layers): Sequential(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 28388417\n",
      "31 May 11:08    INFO  FLOPs: 24960.0\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "31 May 11:29    INFO  epoch 0 training [time: 1227.70s, train loss: 6181.0007]\n",
      "31 May 11:48    INFO  epoch 1 training [time: 1188.95s, train loss: 4719.6027]\n",
      "31 May 12:08    INFO  epoch 2 training [time: 1189.37s, train loss: 4335.5745]\n",
      "31 May 12:28    INFO  epoch 3 training [time: 1195.60s, train loss: 4155.9738]\n",
      "31 May 12:48    INFO  epoch 4 training [time: 1195.58s, train loss: 4046.8818]\n",
      "31 May 12:50    INFO  epoch 4 evaluating [time: 139.96s, valid_score: 0.945300]\n",
      "31 May 12:50    INFO  valid result: \n",
      "recall@10 : 0.8936    ndcg@10 : 0.9453    mrr@10 : 0.9604\n",
      "31 May 12:51    INFO  Saving current: saved_models_ml25m_ranking/NeuMF-May-31-2025_11-08-41.pth\n",
      "31 May 13:10    INFO  epoch 5 training [time: 1167.62s, train loss: 3975.3278]\n",
      "31 May 13:30    INFO  epoch 6 training [time: 1177.90s, train loss: 3917.1133]\n",
      "31 May 13:49    INFO  epoch 7 training [time: 1164.77s, train loss: 3875.4026]\n",
      "31 May 14:08    INFO  epoch 8 training [time: 1166.36s, train loss: 3823.6742]\n",
      "31 May 14:28    INFO  epoch 9 training [time: 1166.46s, train loss: 3789.0804]\n",
      "31 May 14:30    INFO  epoch 9 evaluating [time: 134.81s, valid_score: 0.947300]\n",
      "31 May 14:30    INFO  valid result: \n",
      "recall@10 : 0.8941    ndcg@10 : 0.9473    mrr@10 : 0.9628\n",
      "31 May 14:30    INFO  Saving current: saved_models_ml25m_ranking/NeuMF-May-31-2025_11-08-41.pth\n",
      "31 May 14:50    INFO  epoch 10 training [time: 1189.17s, train loss: 3748.0825]\n",
      "31 May 15:10    INFO  epoch 11 training [time: 1194.37s, train loss: 3719.8865]\n",
      "31 May 15:30    INFO  epoch 12 training [time: 1194.75s, train loss: 3689.0542]\n",
      "31 May 15:50    INFO  epoch 13 training [time: 1194.93s, train loss: 3669.2649]\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/_weights_only_unpickler.py:549: UserWarning: Detected pickle protocol 4 in the checkpoint, which was not the default pickle protocol used by `torch.load` (2). The weights_only Unpickler might not support all instructions implemented by this protocol, please file an issue for adding support if you encounter this.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer, dataset, dataloaders = \u001b[43mrun_recbole\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining complete. Logs saved to:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[33m'\u001b[39m\u001b[33mlog_file\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/quick_start/quick_start.py:153\u001b[39m, in \u001b[36mrun_recbole\u001b[39m\u001b[34m(model, dataset, config_file_list, config_dict, saved, queue)\u001b[39m\n\u001b[32m    148\u001b[39m best_valid_score, best_valid_result = trainer.fit(\n\u001b[32m    149\u001b[39m     train_data, valid_data, saved=saved, show_progress=config[\u001b[33m\"\u001b[39m\u001b[33mshow_progress\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    150\u001b[39m )\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# model evaluation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m test_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43msaved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshow_progress\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m environment_tb = get_environment(config)\n\u001b[32m    158\u001b[39m logger.info(\n\u001b[32m    159\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe running environment of this training is as follows:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m     + environment_tb.draw()\n\u001b[32m    161\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/trainer/trainer.py:583\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_data, load_best_model, model_file, show_progress)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load_best_model:\n\u001b[32m    582\u001b[39m     checkpoint_file = model_file \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.saved_model_file\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.load_state_dict(checkpoint[\u001b[33m\"\u001b[39m\u001b[33mstate_dict\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    585\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.load_other_parameter(checkpoint.get(\u001b[33m\"\u001b[39m\u001b[33mother_parameter\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/torch/serialization.py:1524\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1516\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1517\u001b[39m                     opened_zipfile,\n\u001b[32m   1518\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1521\u001b[39m                     **pickle_load_args,\n\u001b[32m   1522\u001b[39m                 )\n\u001b[32m   1523\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1526\u001b[39m             opened_zipfile,\n\u001b[32m   1527\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m             **pickle_load_args,\n\u001b[32m   1531\u001b[39m         )\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer, dataset, dataloaders = run_recbole(config_dict=config_dict)\n",
    "\n",
    "print(\"\\nTraining complete. Logs saved to:\")\n",
    "print(f\"  {config_dict['log_file']}\")\n",
    "print(f\"Best model saved in: {config_dict['checkpoint_dir']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39826c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Prediction for One User ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Example Prediction for one user ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Example Prediction for One User ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtrainer\u001b[49m.best_model_path \u001b[38;5;129;01mand\u001b[39;00m os.path.exists(trainer.best_model_path):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading best model from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.best_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     config_loaded = Config(model=config_dict[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m], dataset=config_dict[\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m], config_dict=config_dict)\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- Example Prediction for one user ---\n",
    "print(\"\\n--- Example Prediction for One User ---\")\n",
    "\n",
    "if trainer.best_model_path and os.path.exists(trainer.best_model_path):\n",
    "    print(f\"Loading best model from: {trainer.best_model_path}\")\n",
    "    \n",
    "    config_loaded = Config(model=config_dict['model'], dataset=config_dict['dataset'], config_dict=config_dict)\n",
    "    model_loaded = NeuMF(config_loaded, dataset).to(config_loaded.device)\n",
    "    model_loaded.load_state_dict(torch.load(trainer.best_model_path)['state_dict'])\n",
    "    model_loaded.eval()\n",
    "\n",
    "    uid_field = dataset.uid_field\n",
    "    iid_field = dataset.iid_field\n",
    "    \n",
    "    user_id_internal = None\n",
    "    if dataloaders and len(dataloaders) > 2 and dataloaders[2].dataset:\n",
    "            for interaction_batch in dataloaders[2]:\n",
    "                if interaction_batch[uid_field].numel() > 0:\n",
    "                    user_id_internal = interaction_batch[uid_field][0].item()\n",
    "                    if user_id_internal != 0:\n",
    "                        break\n",
    "            if user_id_internal == 0:\n",
    "                user_id_internal = None\n",
    "                for interaction_batch in dataloaders[2]:\n",
    "                    for uid_tensor in interaction_batch[uid_field]:\n",
    "                        if uid_tensor.item() != 0:\n",
    "                            user_id_internal = uid_tensor.item()\n",
    "                            break\n",
    "                    if user_id_internal is not None:\n",
    "                        break\n",
    "    \n",
    "    if user_id_internal is None:\n",
    "        print(\"Could not find a valid user for example prediction in the test set.\")\n",
    "    else:\n",
    "        original_user_id = dataset.id2token(uid_field)[user_id_internal]\n",
    "        print(f\"\\nExample Predictions for User (Original ID): {original_user_id}\")\n",
    "        print(f\"Example Predictions for User (RecBole Internal ID): {user_id_internal}\")\n",
    "\n",
    "        all_item_ids_internal = dataset.token2id(iid_field).values()\n",
    "        all_item_ids_internal = [item_id for item_id in all_item_ids_internal if item_id != 0]\n",
    "\n",
    "        user_interacted_items_internal = set()\n",
    "        for loader in dataloaders:\n",
    "            for item_id_tensor in loader.dataset.get_user_item_feedback(user_id_internal).keys():\n",
    "                user_interacted_items_internal.add(item_id_tensor)\n",
    "\n",
    "        candidate_items_internal = [item_id for item_id in all_item_ids_internal if item_id not in user_interacted_items_internal]\n",
    "        \n",
    "        import random\n",
    "        if len(candidate_items_internal) > 20:\n",
    "            candidate_items_internal = random.sample(candidate_items_internal, 20)\n",
    "        elif not candidate_items_internal:\n",
    "            print(\"No candidate movies found for prediction (user might have rated all movies).\")\n",
    "            candidate_items_internal = random.sample(all_item_ids_internal, min(len(all_item_ids_internal), 10))\n",
    "            print(\"Predicting for random movies, even if the user might have interacted with them.\")\n",
    "\n",
    "\n",
    "        if not candidate_items_internal:\n",
    "            print(\"Cannot perform predictions. No available candidate movies.\")\n",
    "        else:\n",
    "            inter_dict = {\n",
    "                uid_field: torch.tensor([user_id_internal] * len(candidate_items_internal), dtype=torch.long, device=config_loaded.device),\n",
    "                iid_field: torch.tensor(candidate_items_internal, dtype=torch.long, device=config_loaded.device),\n",
    "            }\n",
    "            predict_interaction = Interaction(inter_dict)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # For ranking, predict() returns a score (higher is better)\n",
    "                scores = model_loaded.predict(predict_interaction)\n",
    "                # Sort items by predicted score in descending order\n",
    "                ranked_indices = torch.argsort(scores, descending=True)\n",
    "                \n",
    "                print(\"\\nTop 5 Recommended Movies (by predicted score):\")\n",
    "                for i in range(min(5, len(ranked_indices))):\n",
    "                    idx = ranked_indices[i].item()\n",
    "                    item_id_internal = candidate_items_internal[idx]\n",
    "                    original_item_id = dataset.id2token(iid_field)[item_id_internal]\n",
    "                    predicted_score = scores[idx].item()\n",
    "                    print(f\"  Movie {original_item_id}: Score {predicted_score:.4f}\")\n",
    "else:\n",
    "    print(\"Could not load best model for example prediction. Training might not have completed successfully or model was not saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
