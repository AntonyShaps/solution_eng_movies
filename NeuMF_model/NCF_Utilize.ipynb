{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2b5232",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79213841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-03 00:05:40,176\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-06-03 00:05:40,559\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "# Python 3.11 required (code will not work with Python 3.12 or 3.13 because of a bug in the ReCBOLE library)\n",
    "# Rebole version 1.2.1 is required ------- available for Python 3.11\n",
    "\n",
    "import torch\n",
    "from recbole.quick_start import load_data_and_model\n",
    "from recbole.data.interaction import Interaction\n",
    "from recbole.data.utils import create_dataset\n",
    "from recbole.config import Config # Import Config\n",
    "import pandas as pd\n",
    "import os \n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffbcc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c0858c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a USER ID for predictions\n",
    "user_raw_id_to_predict = '345'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f382da",
   "metadata": {},
   "source": [
    "## 1) Model version 5: predictions\n",
    "\n",
    "The model training lasts 50 epochs with 'uni100' evaluation mode (but the model saved after 40th epoch to avoid overfitting)\n",
    "\n",
    "(the duration of training & evaluation was about **18 hours**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffcf633",
   "metadata": {},
   "source": [
    "### 1.1 Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54bda046",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_config_dict = {\n",
    "    'model': 'NeuMF',\n",
    "    'dataset': 'movielens',\n",
    "    'data_path': '../movies-database/',\n",
    "\n",
    "  'field_separator': '\\t',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "    'LABEL_FIELD': 'rating', \n",
    "    'threshold': {'rating': 4.5}, \n",
    "\n",
    "    'eval_task': 'ranking', \n",
    "    'normalize_field': {},\n",
    "    'loss_type': 'BPR', \n",
    "\n",
    "    'eval_args': {\n",
    "        'split': {'RS': [0.9, 0.05, 0.05]},\n",
    "        'order': 'TO',\n",
    "        'group_by': 'user',\n",
    "        'mode': {'valid': 'uni100', 'test': 'uni100'},\n",
    "        'neg_sample_args': None, \n",
    "        'topk': [3, 10, 20], \n",
    "    },\n",
    "    'metrics': ['Recall', 'NDCG', 'MRR'], \n",
    "    'valid_metric': 'NDCG@10',\n",
    "    'valid_metric_bigger': True,\n",
    "\n",
    "    'train_neg_sample_args': {'distribution': 'uniform', 'sample_num': 1}, \n",
    "    'mf_embedding_size': 64,\n",
    "    'mlp_embedding_size': 64,\n",
    "    'layers': [128, 64, 32],\n",
    "    'dropout_prob': 0.3,\n",
    "\n",
    "    'learning_rate': 0.001,\n",
    "    'train_batch_size': 1024,\n",
    "    'epochs': 50,\n",
    "    'eval_step': 5,\n",
    "    'stopping_step': 4,\n",
    "\n",
    "    'eval_batch_size': 512,\n",
    "    'log_wandb': False,\n",
    "    'show_progress': False,\n",
    "    'log_file': 'main_NeuMF.txt',\n",
    "    'checkpoint_dir': 'main_NeuMF',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a2d50e",
   "metadata": {},
   "source": [
    "### 1.2 Execute model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "484ce436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Model 'NeuMF' initialized.\n",
      "Model state dictionary loaded successfully.\n",
      "MF User Embedding Weight Mean: -0.1944\n",
      "MLP Item Embedding Weight Mean: -0.0596\n",
      "Prediction Layer Weight Mean: -0.0093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuMF(\n",
       "  (user_mf_embedding): Embedding(162542, 64)\n",
       "  (item_mf_embedding): Embedding(59048, 64)\n",
       "  (user_mlp_embedding): Embedding(162542, 64)\n",
       "  (item_mlp_embedding): Embedding(59048, 64)\n",
       "  (mlp_layers): MLPLayers(\n",
       "    (mlp_layers): Sequential(\n",
       "      (0): Dropout(p=0.3, inplace=False)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.3, inplace=False)\n",
       "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "saved_model_path = './NeuMF-May-31-2025_23-14-35.pth' \n",
    "\n",
    "config = Config(model=prediction_config_dict['model'], dataset=prediction_config_dict['dataset'], config_dict=prediction_config_dict)\n",
    "dataset = create_dataset(config)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "model_name = config['model']\n",
    "model_module = importlib.import_module(f\"recbole.model.general_recommender\")\n",
    "model_class = getattr(model_module, model_name)\n",
    "\n",
    "model = model_class(config, dataset)\n",
    "print(f\"Model '{model_name}' initialized.\")\n",
    "\n",
    "checkpoint = torch.load(saved_model_path, weights_only=False)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model state dictionary loaded successfully.\")\n",
    "\n",
    "# small paragraph about model weights ---\n",
    "print(f\"MF User Embedding Weight Mean: {model.user_mf_embedding.weight.mean().item():.4f}\")\n",
    "print(f\"MLP Item Embedding Weight Mean: {model.item_mlp_embedding.weight.mean().item():.4f}\")\n",
    "print(f\"Prediction Layer Weight Mean: {model.predict_layer.weight.mean().item():.4f}\")\n",
    "# --- end of small paragraph ---\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dedd44",
   "metadata": {},
   "source": [
    "### 1.3 Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23b5e1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing predictions for user: '345' ---\n",
      "User 345 has interacted with 340 items via manual filtering.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a USER ID\n",
    "#user_raw_id_to_predict = '345'\n",
    "\n",
    "print(f\"\\n--- Preparing predictions for user: '{user_raw_id_to_predict}' ---\")\n",
    "\n",
    "user_internal_id = dataset.token2id(dataset.uid_field, user_raw_id_to_predict)\n",
    "\n",
    "all_item_internal_ids = torch.arange(dataset.item_num, dtype=torch.long).tolist()\n",
    "\n",
    "all_interactions = dataset.inter_feat\n",
    "user_ids_tensor = all_interactions[dataset.uid_field]\n",
    "item_ids_tensor = all_interactions[dataset.iid_field]\n",
    "user_mask = (user_ids_tensor == user_internal_id)\n",
    "interacted_items_tensor = item_ids_tensor[user_mask]\n",
    "user_interacted_items_internal_ids = set(interacted_items_tensor.tolist())\n",
    "print(f\"User {user_raw_id_to_predict} has interacted with {len(user_interacted_items_internal_ids)} items via manual filtering.\")\n",
    "\n",
    "# Filter to get only the unrated items\n",
    "unrated_item_internal_ids = [\n",
    "    item_id for item_id in all_item_internal_ids\n",
    "    if item_id not in user_interacted_items_internal_ids\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d471a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 3 Predicted Ratings for User '345' ---\n",
      "    item_id  predicted_rating\n",
      "232    2959          0.999935\n",
      "228    2329          0.999676\n",
      "158    4993          0.999579\n",
      "\n",
      "--- Bottom 3 Predicted Ratings for User '345' ---\n",
      "      item_id  predicted_rating\n",
      "44186  178911      6.871721e-10\n",
      "31696  181895      5.355051e-10\n",
      "19628  158942      4.342869e-10\n",
      "\n",
      "--- Number of Highly recommended films (>0.99) for User '345' ---\n",
      "item_id             171\n",
      "predicted_rating    171\n",
      "dtype: int64\n",
      "\n",
      "--- Number of not recommended films (<0.01) for User '345' ---\n",
      "item_id             51950\n",
      "predicted_rating    51950\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare tensors for prediction\n",
    "user_tensor_for_prediction = torch.full(\n",
    "    (len(unrated_item_internal_ids),),\n",
    "    user_internal_id,\n",
    "    dtype=torch.long\n",
    ")\n",
    "item_tensor_for_prediction = torch.tensor(\n",
    "    unrated_item_internal_ids,\n",
    "    dtype=torch.long\n",
    ")\n",
    "\n",
    "# Create an Interaction object - this is the STANDARD input for RecBole models\n",
    "interaction_for_prediction = Interaction({\n",
    "    # Use the field names directly as keys for the Interaction object\n",
    "    config.USER_ID_FIELD: user_tensor_for_prediction,\n",
    "    config.ITEM_ID_FIELD: item_tensor_for_prediction \n",
    "})\n",
    "\n",
    "## Make predictions\n",
    "with torch.no_grad(): \n",
    "    predicted_scores = model.predict(interaction_for_prediction)\n",
    "\n",
    "#  Map internal item IDs back to raw IDs and display results\n",
    "predictions = []\n",
    "for i, score in enumerate(predicted_scores):\n",
    "    item_internal_id = unrated_item_internal_ids[i]\n",
    "    item_raw_id = dataset.id2token(dataset.iid_field, item_internal_id)\n",
    "    predictions.append({'item_id': item_raw_id, 'predicted_rating': score.item()})\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions).sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "print(f\"\\n--- Top 3 Predicted Ratings for User '{user_raw_id_to_predict}' ---\")\n",
    "print(predictions_df.head(3))\n",
    "\n",
    "print(f\"\\n--- Bottom 3 Predicted Ratings for User '{user_raw_id_to_predict}' ---\")\n",
    "print(predictions_df.tail(3))\n",
    "\n",
    "print(f\"\\n--- Number of Highly recommended films (>0.99) for User '{user_raw_id_to_predict}' ---\")\n",
    "print(predictions_df[predictions_df['predicted_rating'] > 0.99].count())\n",
    "\n",
    "print(f\"\\n--- Number of not recommended films (<0.01) for User '{user_raw_id_to_predict}' ---\")\n",
    "print(predictions_df[predictions_df['predicted_rating'] < 0.01].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00d2886c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF User Embedding Weight Mean: -0.1944\n",
      "MLP Item Embedding Weight Mean: -0.0596\n",
      "Prediction Layer Weight Mean: -0.0093\n"
     ]
    }
   ],
   "source": [
    "print(f\"MF User Embedding Weight Mean: {model.user_mf_embedding.weight.mean().item():.4f}\")\n",
    "print(f\"MLP Item Embedding Weight Mean: {model.item_mlp_embedding.weight.mean().item():.4f}\")\n",
    "print(f\"Prediction Layer Weight Mean: {model.predict_layer.weight.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76b9e83",
   "metadata": {},
   "source": [
    "## 2) Model version 4: predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9677cd",
   "metadata": {},
   "source": [
    "The model training lasts 14 epochs with 'uni10' evaluation mode \n",
    "\n",
    "(the duration of training & evaluation was about 6 hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22fcf3e",
   "metadata": {},
   "source": [
    "### 2.1 Model configuration and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68ca4eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/opt/miniconda3/envs/recbole_new_env/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Model 'NeuMF' initialized.\n",
      "Model state dictionary loaded successfully.\n",
      "MF User Embedding Weight Mean: 0.0037\n",
      "MLP Item Embedding Weight Mean: 0.0544\n",
      "Prediction Layer Weight Mean: -0.0137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuMF(\n",
       "  (user_mf_embedding): Embedding(162542, 64)\n",
       "  (item_mf_embedding): Embedding(59048, 64)\n",
       "  (user_mlp_embedding): Embedding(162542, 64)\n",
       "  (item_mlp_embedding): Embedding(59048, 64)\n",
       "  (mlp_layers): MLPLayers(\n",
       "    (mlp_layers): Sequential(\n",
       "      (0): Dropout(p=0.3, inplace=False)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.3, inplace=False)\n",
       "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (predict_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_config_dict_2 = {\n",
    "    'model': 'NeuMF',\n",
    "    'dataset': 'movielens',\n",
    "    'data_path': '../movies-database/',\n",
    "\n",
    "  'field_separator': '\\t',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "\n",
    "    'load_col': {\n",
    "        'inter': ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    },\n",
    "    'LABEL_FIELD': 'rating', \n",
    "    'threshold': {'rating': 4.5}, #  Ratings >= 4.5 are positive interactions for ranking\n",
    "\n",
    "    'eval_task': 'ranking', \n",
    "    'normalize_field': {},\n",
    "    'loss_type': 'BPR', \n",
    "\n",
    "    'eval_args': {\n",
    "        'split': {'RS': [0.9, 0.05, 0.05]},\n",
    "        'order': 'TO',\n",
    "        'group_by': 'user',\n",
    "        'mode': {'valid': 'uni10', 'test': 'uni10'},\n",
    "        'neg_sample_args': None, \n",
    "        'topk': [10, 20, 50], \n",
    "    },\n",
    "\n",
    "    'metrics': ['Recall', 'NDCG', 'MRR'], \n",
    "    'valid_metric': 'NDCG@10', \n",
    "    'valid_metric_bigger': True,\n",
    "\n",
    "    'train_neg_sample_args': {'distribution': 'uniform', 'sample_num': 1}, \n",
    "    \n",
    "    'mf_embedding_size': 64,\n",
    "    'mlp_embedding_size': 64,\n",
    "    'layers': [128, 64, 32],\n",
    "    'dropout_prob': 0.3,\n",
    "\n",
    "    'learning_rate': 0.001,\n",
    "    'train_batch_size': 1024,\n",
    "    'epochs': 14,\n",
    "    'eval_step': 5,\n",
    "\n",
    "    'eval_batch_size': 512,\n",
    "    'log_wandb': False,\n",
    "    'show_progress': False,\n",
    "    'log_file': 'recbole_ml25m_neumf_ranking_log.txt', \n",
    "    'checkpoint_dir': 'saved_models_ml25m_ranking',\n",
    "}\n",
    "\n",
    "saved_model_path_2 = './NeuMF-May-31-2025_11-08-41.pth'  ## <---- model path\n",
    "\n",
    "config = Config(model=prediction_config_dict_2['model'], dataset=prediction_config_dict_2['dataset'], config_dict=prediction_config_dict_2)\n",
    "dataset = create_dataset(config)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "model_name = config['model']\n",
    "model_module = importlib.import_module(f\"recbole.model.general_recommender\")\n",
    "model_class = getattr(model_module, model_name)\n",
    "\n",
    "model_2 = model_class(config, dataset)\n",
    "print(f\"Model '{model_name}' initialized.\")\n",
    "\n",
    "checkpoint = torch.load(saved_model_path_2, weights_only=False)\n",
    "model_2.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model state dictionary loaded successfully.\")\n",
    "\n",
    "# small paragraph about model weights ---\n",
    "print(f\"MF User Embedding Weight Mean: {model_2.user_mf_embedding.weight.mean().item():.4f}\")\n",
    "print(f\"MLP Item Embedding Weight Mean: {model_2.item_mlp_embedding.weight.mean().item():.4f}\")\n",
    "print(f\"Prediction Layer Weight Mean: {model_2.predict_layer.weight.mean().item():.4f}\")\n",
    "# --- end of small paragraph ---\n",
    "\n",
    "model_2.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb9f77",
   "metadata": {},
   "source": [
    "### 2.2 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b23d6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing predictions for user: '345' ---\n",
      "User 345 has interacted with 340 items via manual filtering.\n",
      "\n",
      "--- Top 3 Predicted Ratings for User '345' ---\n",
      "     item_id  predicted_rating\n",
      "232     2959          0.999828\n",
      "1382    3897          0.999680\n",
      "228     2329          0.999637\n",
      "\n",
      "--- Bottom 3 Predicted Ratings for User '345' ---\n",
      "      item_id  predicted_rating\n",
      "56697  169558      8.658309e-08\n",
      "33754  140104      8.468910e-08\n",
      "37328  180583      8.282374e-08\n",
      "\n",
      "--- Number of Highly recommended films (>0.99) for User '345' ---\n",
      "item_id             250\n",
      "predicted_rating    250\n",
      "dtype: int64\n",
      "\n",
      "--- Number of not recommended films (<0.01) for User '345' ---\n",
      "item_id             51041\n",
      "predicted_rating    51041\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a USER ID\n",
    "#user_raw_id_to_predict = '345'\n",
    "\n",
    "print(f\"\\n--- Preparing predictions for user: '{user_raw_id_to_predict}' ---\")\n",
    "\n",
    "user_internal_id = dataset.token2id(dataset.uid_field, user_raw_id_to_predict)\n",
    "\n",
    "all_item_internal_ids = torch.arange(dataset.item_num, dtype=torch.long).tolist()\n",
    "\n",
    "all_interactions = dataset.inter_feat\n",
    "user_ids_tensor = all_interactions[dataset.uid_field]\n",
    "item_ids_tensor = all_interactions[dataset.iid_field]\n",
    "user_mask = (user_ids_tensor == user_internal_id)\n",
    "interacted_items_tensor = item_ids_tensor[user_mask]\n",
    "user_interacted_items_internal_ids = set(interacted_items_tensor.tolist())\n",
    "print(f\"User {user_raw_id_to_predict} has interacted with {len(user_interacted_items_internal_ids)} items via manual filtering.\")\n",
    "\n",
    "# Filter to get only the unrated items\n",
    "unrated_item_internal_ids = [\n",
    "    item_id for item_id in all_item_internal_ids\n",
    "    if item_id not in user_interacted_items_internal_ids\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Prepare tensors for prediction\n",
    "user_tensor_for_prediction = torch.full(\n",
    "    (len(unrated_item_internal_ids),),\n",
    "    user_internal_id,\n",
    "    dtype=torch.long\n",
    ")\n",
    "item_tensor_for_prediction = torch.tensor(\n",
    "    unrated_item_internal_ids,\n",
    "    dtype=torch.long\n",
    ")\n",
    "\n",
    "# Create an Interaction object - this is the STANDARD input for RecBole models\n",
    "interaction_for_prediction = Interaction({\n",
    "    # Use the field names directly as keys for the Interaction object\n",
    "    config.USER_ID_FIELD: user_tensor_for_prediction,\n",
    "    config.ITEM_ID_FIELD: item_tensor_for_prediction \n",
    "})\n",
    "\n",
    "## Make predictions\n",
    "with torch.no_grad(): \n",
    "    predicted_scores = model_2.predict(interaction_for_prediction)\n",
    "\n",
    "#  Map internal item IDs back to raw IDs and display results\n",
    "predictions = []\n",
    "for i, score in enumerate(predicted_scores):\n",
    "    item_internal_id = unrated_item_internal_ids[i]\n",
    "    item_raw_id = dataset.id2token(dataset.iid_field, item_internal_id)\n",
    "    predictions.append({'item_id': item_raw_id, 'predicted_rating': score.item()})\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions).sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "print(f\"\\n--- Top 3 Predicted Ratings for User '{user_raw_id_to_predict}' ---\")\n",
    "print(predictions_df.head(3))\n",
    "\n",
    "print(f\"\\n--- Bottom 3 Predicted Ratings for User '{user_raw_id_to_predict}' ---\")\n",
    "print(predictions_df.tail(3))\n",
    "\n",
    "print(f\"\\n--- Number of Highly recommended films (>0.99) for User '{user_raw_id_to_predict}' ---\")\n",
    "print(predictions_df[predictions_df['predicted_rating'] > 0.99].count())\n",
    "\n",
    "print(f\"\\n--- Number of not recommended films (<0.01) for User '{user_raw_id_to_predict}' ---\")\n",
    "print(predictions_df[predictions_df['predicted_rating'] < 0.01].count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970250f",
   "metadata": {},
   "source": [
    "Movies with ID 2959 and 2329 were recomended by both variations of the NeuMF model. \n",
    "\n",
    "Overall, **the 5th version of the model** (whoose predictions observed first) is slightly better since it strongly recommend (>0.99) lower number of movies then **the 4th version of the model** (171 against 250 items respectivelly).\n",
    "\n",
    "The recall@10 is better for **the 4th version of the model**, but this metric **for the 5th version of the model** was calculated much more appropriatelly (based on sample of 100 instead of 10 movies), so we cannot compare models based on this metric."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
